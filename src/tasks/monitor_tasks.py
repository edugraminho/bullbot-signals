"""
Tasks principais de monitoramento RSI
"""

import asyncio
import time
from datetime import datetime, timedelta, timezone
from typing import List, Optional

from celery import group

from src.core.services.rsi_service import RSIService
from src.core.services.signal_filter import signal_filter
from src.database.connection import SessionLocal
from src.database.models import MonitoringConfig, SignalHistory
from src.tasks.celery_app import celery_app
from src.utils.config import settings
from src.utils.logger import get_logger
from src.utils.trading_coins import trading_coins

logger = get_logger(__name__, level="INFO")


class MonitorTaskConfig:
    """Configura√ß√£o para tasks de monitoramento"""

    def __init__(self):
        self.rsi_window = settings.rsi_calculation_window
        self.rsi_timeframe = settings.rsi_analysis_timeframe
        self.max_retries = settings.task_max_retry_attempts
        self.retry_countdown = settings.task_retry_delay_seconds
        self.cleanup_days = settings.signal_history_retention_days
        self.default_symbols = settings.default_crypto_symbols


# Inst√¢ncia global de configura√ß√£o
task_config = MonitorTaskConfig()


@celery_app.task(bind=True)
def update_trading_coins(self):
    """
    Task para atualizar lista de trading coins - executa a cada 7 dias
    """
    try:
        logger.info("Iniciando atualiza√ß√£o da lista de trading coins")

        # Executar atualiza√ß√£o
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            coins = loop.run_until_complete(trading_coins.update_trading_list())

            if coins:
                logger.info(
                    f"Lista de trading coins atualizada com {len(coins)} moedas"
                )

                return {
                    "status": "success",
                    "total_coins": len(coins),
                    "message": f"Lista atualizada com {len(coins)} moedas",
                }
            else:
                logger.error("Falha ao atualizar lista de trading coins")
                return {"status": "error", "message": "Falha ao atualizar lista"}

        finally:
            loop.close()

    except Exception as e:
        logger.error(f"‚ùå Erro na atualiza√ß√£o de trading coins: {e}")

        if self.request.retries < task_config.max_retries:
            logger.info(
                f"Reagendando atualiza√ß√£o de trading coins (tentativa {self.request.retries + 1})"
            )
            raise self.retry(countdown=task_config.retry_countdown, exc=e)

        return {"status": "error", "error": str(e)}


@celery_app.task(bind=True)
def monitor_rsi_signals(self):
    """
    Task principal de monitoramento - executa sequencialmente
    Agenda pr√≥xima execu√ß√£o 1 minuto ap√≥s t√©rmino
    """
    cycle_start_time = time.time()

    try:
        logger.info("=" * 60)
        logger.info("üöÄ INICIANDO CICLO DE MONITORAMENTO RSI üöÄ")
        logger.info("=" * 60)

        # Obter configura√ß√£o ativa
        symbols = get_active_symbols()
        if not symbols:
            logger.warning("Nenhum s√≠mbolo configurado para monitoramento")
            # Agendar pr√≥xima execu√ß√£o mesmo sem s√≠mbolos
            self.apply_async(countdown=60)
            return {"status": "no_symbols"}

        # Distribuir s√≠mbolos por exchange para rate limiting
        symbol_batches = distribute_symbols_by_exchange(symbols)

        # Criar chain sequencial de tasks
        from celery import chord

        # Filtrar exchanges com s√≠mbolos
        exchanges_with_symbols = {
            exchange: batch_symbols
            for exchange, batch_symbols in symbol_batches.items()
            if batch_symbols
        }

        if not exchanges_with_symbols:
            logger.warning("Nenhuma exchange com s√≠mbolos para processar")
            # Agendar pr√≥xima execu√ß√£o mesmo sem exchanges
            self.apply_async(countdown=60)
            return {"status": "no_exchanges"}

        # Criar lista de tasks para executar
        tasks_list = []
        for exchange, batch_symbols in exchanges_with_symbols.items():
            logger.info(f"üîÑ Preparando {exchange} ({len(batch_symbols)} s√≠mbolos)...")
            tasks_list.append(process_symbol_batch.s(exchange, batch_symbols))

        # Usar chord para executar sequencialmente e aguardar resultados

        callback = finalize_monitoring_cycle.s(
            cycle_start_time=cycle_start_time,
            total_symbols=len(symbols),
            total_exchanges=len(exchanges_with_symbols),
        ).set(link=schedule_next_monitoring.s())

        chord(tasks_list, callback).apply_async()

        cycle_duration = time.time() - cycle_start_time
        logger.info(
            f"‚úÖ Chord iniciado: {len(symbols)} s√≠mbolos em {len(exchanges_with_symbols)} exchanges "
            f"(inicializa√ß√£o: {cycle_duration:.2f}s)"
        )
        logger.info("-" * 60)

        return {
            "status": "chord_started",
            "total_symbols": len(symbols),
            "exchanges": len(exchanges_with_symbols),
            "cycle_start_time": cycle_start_time,
            "processing_mode": "sequential_chord",
        }

    except Exception as e:
        cycle_duration = time.time() - cycle_start_time
        logger.error(
            f"‚ùå Erro no monitoramento sequencial: {e} (ciclo: {cycle_duration:.2f}s)"
        )
        # Agendar pr√≥xima execu√ß√£o mesmo em caso de erro
        self.apply_async(countdown=60)
        return {"status": "error", "error": str(e)}


@celery_app.task(bind=True, max_retries=2)
def process_symbol_batch(self, exchange: str, symbols: List[str]):
    """
    Processar batch de s√≠mbolos para uma exchange espec√≠fica

    Args:
        exchange: Nome da exchange (binance, gate, mexc)
        symbols: Lista de s√≠mbolos para processar
    """
    batch_start_time = time.time()

    try:
        logger.info(f"üîÑ Processando {len(symbols)} s√≠mbolos na {exchange}")

        # Carregar configura√ß√µes de monitoramento do banco
        monitoring_config = get_active_monitoring_config()

        # Criar RSIService com configura√ß√µes personalizadas se dispon√≠vel
        if monitoring_config:
            from src.core.models.crypto import RSILevels

            custom_rsi_levels = RSILevels(
                oversold=monitoring_config.rsi_oversold,
                overbought=monitoring_config.rsi_overbought,
            )
            rsi_service = RSIService(custom_rsi_levels=custom_rsi_levels)
        else:
            # config.py
            rsi_service = RSIService()

        # Processar cada s√≠mbolo
        results = []
        successful = 0
        filtered = 0
        errors = 0
        no_data = 0

        for i, symbol in enumerate(symbols, 1):
            symbol_start_time = time.time()

            result = process_single_symbol(
                symbol=symbol,
                exchange=exchange,
                rsi_service=rsi_service,
                rsi_window=task_config.rsi_window,
                rsi_timeframe=task_config.rsi_timeframe,
            )

            # Contar estat√≠sticas
            if result.get("status") == "signal_sent":
                successful += 1
            elif result.get("status") == "filtered":
                filtered += 1
            elif result.get("status") == "no_data":
                no_data += 1
            else:
                errors += 1

            results.append(result)

            # Log de progresso a cada 10 s√≠mbolos
            if i % 10 == 0 or i == len(symbols):
                symbol_duration = time.time() - symbol_start_time
                logger.info(
                    f"üìä {exchange}: {i}/{len(symbols)} s√≠mbolos processados "
                    f"({symbol_duration:.2f}s/s√≠mbolo)"
                )

        batch_duration = time.time() - batch_start_time
        avg_time_per_symbol = batch_duration / len(symbols) if symbols else 0

        logger.info(
            f"‚úÖ Batch {exchange} conclu√≠do: {successful}/{len(symbols)} sucessos "
            f"({batch_duration:.2f}s total, {avg_time_per_symbol:.2f}s/moeda)"
        )
        logger.info("-" * 40)

        return {
            "status": "completed",
            "exchange": exchange,
            "total": len(symbols),
            "successful": successful,
            "filtered": filtered,
            "errors": errors,
            "no_data": no_data,
            "duration": batch_duration,
            "avg_time_per_symbol": avg_time_per_symbol,
        }

    except Exception as e:
        batch_duration = time.time() - batch_start_time
        logger.error(
            f"‚ùå Erro no batch {exchange}: {e} (dura√ß√£o: {batch_duration:.2f}s)"
        )

        if self.request.retries < task_config.max_retries:
            logger.info(
                f"üîÑ Reagendando batch {exchange} (tentativa {self.request.retries + 1})"
            )
            raise self.retry(countdown=task_config.retry_countdown, exc=e)

        return {"status": "error", "error": str(e)}


def process_single_symbol(
    symbol: str,
    exchange: str,
    rsi_service: RSIService,
    rsi_window: int,
    rsi_timeframe: str,
) -> dict:
    """
    Processar um √∫nico s√≠mbolo

    Args:
        symbol: S√≠mbolo da crypto
        exchange: Exchange para buscar dados
        rsi_service: Inst√¢ncia do servi√ßo RSI

    Returns:
        Resultado do processamento
    """
    symbol_start_time = time.time()  # Adicionar timing para processamento

    try:
        # Buscar RSI (usando async em context)
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        rsi_data = loop.run_until_complete(
            rsi_service.get_rsi(symbol, rsi_timeframe, rsi_window, exchange)
        )

        if not rsi_data:
            # Moeda n√£o encontrada - remover exchange da lista
            from src.utils.trading_coins import trading_coins

            trading_coins.remove_exchange_from_coin(symbol, exchange)
            logger.debug(f"‚ùå {symbol}: Sem dados na {exchange}")
            return {"status": "no_data", "symbol": symbol, "exchange": exchange}

        # Analisar RSI
        analysis = rsi_service.analyze_rsi(rsi_data)

        # Log breve da moeda e RSI
        logger.debug(
            f"üìä {symbol}: RSI {rsi_data.value:.2f} | Pre√ßo ${rsi_data.current_price}"
        )

        if not analysis:
            logger.debug(f"‚ö™ {symbol}: Zona neutra (RSI: {rsi_data.value:.2f})")
            return {
                "status": "neutral_zone",
                "symbol": symbol,
                "rsi_value": rsi_data.value,
            }

        # Aplicar filtros anti-spam
        should_send = loop.run_until_complete(
            signal_filter.should_send_signal(symbol, analysis)
        )

        if should_send:
            # Marcar sinal como enviado
            loop.run_until_complete(signal_filter.mark_signal_sent(symbol, analysis))

            # Salvar sinal no banco de dados
            try:
                db = SessionLocal()

                # Criar registro do sinal
                signal_record = SignalHistory(
                    symbol=symbol,
                    signal_type=analysis.signal.signal_type.value,
                    strength=analysis.signal.strength.value,
                    price=float(rsi_data.current_price),
                    timeframe=rsi_timeframe,
                    source=exchange,
                    message=f"RSI {float(rsi_data.value):.2f} - {analysis.signal.signal_type.value} signal",
                    indicator_type=["RSI"],
                    indicator_data={
                        "rsi_value": float(rsi_data.value),
                        "rsi_window": rsi_window,
                        "oversold_level": float(rsi_service.rsi_levels.oversold),
                        "overbought_level": float(rsi_service.rsi_levels.overbought),
                    },
                    indicator_config={
                        "rsi_window": rsi_window,
                        "timeframe": rsi_timeframe,
                        "exchange": exchange,
                    },
                    volume_24h=float(rsi_data.volume_24h)
                    if hasattr(rsi_data, "volume_24h")
                    and rsi_data.volume_24h is not None
                    else None,
                    price_change_24h=float(rsi_data.price_change_24h)
                    if hasattr(rsi_data, "price_change_24h")
                    and rsi_data.price_change_24h is not None
                    else None,
                    confidence_score=float(analysis.confidence_score)
                    if hasattr(analysis, "confidence_score")
                    and analysis.confidence_score is not None
                    else None,
                    combined_score=float(analysis.combined_score)
                    if hasattr(analysis, "combined_score")
                    and analysis.combined_score is not None
                    else None,
                    processed=False,  # Aguardando processamento pelo bot do Telegram
                    processing_time_ms=int((time.time() - symbol_start_time) * 1000),
                )

                db.add(signal_record)
                db.commit()
                db.refresh(signal_record)  # Atualizar objeto com ID
                signal_id = signal_record.id
                db.close()

                logger.info(
                    f"üíæ SINAL SALVO NO BANCO: {symbol} | {analysis.signal.signal_type.value} | "
                    f"RSI: {float(rsi_data.value):.2f} | ID: {signal_id}"
                )

            except Exception as db_error:
                logger.error(f"‚ùå Erro ao salvar sinal no banco: {db_error}")
                signal_id = None
                if "db" in locals():
                    db.rollback()
                    db.close()

            logger.info(
                f"üì° üöÄ SINAL DETECTADO: {symbol} | {analysis.signal.signal_type.value} | "
                f"RSI: {float(rsi_data.value):.2f}"
            )

            return {
                "status": "signal_sent",
                "symbol": symbol,
                "signal_type": analysis.signal.signal_type.value,
                "rsi_value": float(rsi_data.value),
                "signal_id": signal_id,
            }

        else:
            logger.debug(f"üîï {symbol}: Sinal filtrado (RSI: {rsi_data.value:.2f})")
            return {"status": "filtered", "symbol": symbol, "rsi_value": rsi_data.value}

    except Exception as e:
        logger.error(f"‚ùå Erro ao processar {symbol} na {exchange}: {e}")
        return {"status": "error", "symbol": symbol, "error": str(e)}

    finally:
        if "loop" in locals():
            loop.close()


def get_active_symbols() -> List[str]:
    """Obter lista de s√≠mbolos ativos para monitoramento"""
    try:
        db = SessionLocal()
        config = (
            db.query(MonitoringConfig).filter(MonitoringConfig.active == True).first()  # noqa: E712
        )

        if config and config.symbols and len(config.symbols) > 0:
            # Usar s√≠mbolos da configura√ß√£o do banco
            symbols = config.symbols
            logger.info(f"üìã Usando {len(symbols)} s√≠mbolos da configura√ß√£o do banco")
        else:
            # Usar lista de trading coins se n√£o h√° configura√ß√£o ou lista vazia
            symbols = trading_coins.get_trading_symbols(limit=500)
            logger.info(f"üìã Usando {len(symbols)} s√≠mbolos da lista de trading coins")

        db.close()
        return symbols

    except Exception as e:
        logger.error(f"‚ùå Erro ao obter s√≠mbolos: {e}")
        # Fallback para lista padr√£o em caso de erro
        return task_config.default_symbols


def get_active_monitoring_config() -> Optional[MonitoringConfig]:
    """Obter configura√ß√£o de monitoramento ativa do banco"""
    try:
        db = SessionLocal()
        config = (
            db.query(MonitoringConfig).filter(MonitoringConfig.active == True).first()  # noqa: E712
        )
        db.close()
        return config
    except Exception as e:
        logger.error(f"‚ùå Erro ao obter configura√ß√£o de monitoramento: {e}")
        return None


def distribute_symbols_by_exchange(symbols: List[str]) -> dict:
    """
    Distribuir s√≠mbolos entre as exchanges baseado na disponibilidade no CSV

    Args:
        symbols: Lista de todos os s√≠mbolos

    Returns:
        Dict com exchange -> lista de s√≠mbolos
    """
    # Carregar dados do CSV para verificar exchanges dispon√≠veis
    coins = trading_coins.load_from_csv()
    coin_exchanges = {coin.symbol: coin.exchanges for coin in coins}

    # Inicializar listas por exchange
    exchange_symbols = {"binance": [], "gate": [], "mexc": []}

    # Distribuir s√≠mbolos baseado nas exchanges dispon√≠veis
    for symbol in symbols:
        available_exchanges = coin_exchanges.get(symbol, [])

        if not available_exchanges:
            # Se n√£o h√° exchanges, pular
            continue

        # Distribuir para a primeira exchange dispon√≠vel
        for exchange in ["binance", "gate", "mexc"]:
            if exchange in available_exchanges:
                exchange_symbols[exchange].append(symbol)
                break

    return exchange_symbols


@celery_app.task
def cleanup_old_signals():
    """Task di√°ria para limpeza de dados antigos"""
    cleanup_start_time = time.time()

    try:
        db = SessionLocal()

        # Remover sinais antigos baseado na configura√ß√£o
        cutoff_date = datetime.now(timezone.utc) - timedelta(
            days=task_config.cleanup_days
        )

        deleted_count = (
            db.query(SignalHistory)
            .filter(SignalHistory.created_at < cutoff_date)
            .delete()
        )

        db.commit()
        db.close()

        cleanup_duration = time.time() - cleanup_start_time
        logger.info(
            f"üßπ Limpeza conclu√≠da: {deleted_count} registros removidos ({cleanup_duration:.2f}s)"
        )

        return {
            "status": "completed",
            "deleted_count": deleted_count,
            "cutoff_date": cutoff_date.isoformat(),
            "duration": cleanup_duration,
        }

    except Exception as e:
        cleanup_duration = time.time() - cleanup_start_time
        logger.error(f"‚ùå Erro na limpeza: {e} (dura√ß√£o: {cleanup_duration:.2f}s)")
        return {"status": "error", "error": str(e)}


@celery_app.task
def finalize_monitoring_cycle(
    *batch_results, cycle_start_time: float, total_symbols: int, total_exchanges: int
):
    """Task para finalizar logs do ciclo de monitoramento sequencial"""
    try:
        cycle_duration = time.time() - cycle_start_time

        # Calcular estat√≠sticas totais dos batches
        total_successful = 0
        total_filtered = 0
        total_errors = 0
        total_no_data = 0

        for result in batch_results:
            if isinstance(result, dict):
                total_successful += result.get("successful", 0)
                total_filtered += result.get("filtered", 0)
                total_errors += result.get("errors", 0)
                total_no_data += result.get("no_data", 0)

        logger.info("-" * 60)
        logger.info("üèÅ CICLO SEQUENCIAL CONCLU√çDO")
        logger.info(
            f"üìä Total: {total_symbols} s√≠mbolos em {total_exchanges} exchanges"
        )
        logger.info(f"‚úÖ Sinais: {total_successful} | üö´ Filtrados: {total_filtered}")
        logger.info(f"‚ùå Erros: {total_errors} | üì≠ Sem dados: {total_no_data}")
        logger.info(f"‚è±Ô∏è Dura√ß√£o total: {cycle_duration:.2f}s")
        logger.info("=" * 60)

        return {
            "status": "cycle_finalized",
            "total_duration": cycle_duration,
            "total_symbols": total_symbols,
            "total_exchanges": total_exchanges,
            "total_successful": total_successful,
            "total_filtered": total_filtered,
            "total_errors": total_errors,
            "total_no_data": total_no_data,
        }

    except Exception as e:
        logger.error(f"‚ùå Erro ao finalizar ciclo: {e}")
        return {"status": "error", "error": str(e)}


@celery_app.task
def schedule_next_monitoring(*args):
    """Task para agendar pr√≥xima execu√ß√£o do monitoramento"""
    try:
        # Agendar pr√≥xima execu√ß√£o em 1 minuto
        monitor_rsi_signals.apply_async(countdown=60)
        logger.info("‚è∞ Pr√≥xima execu√ß√£o agendada em 1 minuto")
        return {"status": "next_scheduled", "delay_seconds": 60}
    except Exception as e:
        logger.error(f"‚ùå Erro ao agendar pr√≥xima execu√ß√£o: {e}")
        return {"status": "error", "error": str(e)}
